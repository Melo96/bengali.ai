{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Copy of DenseNet169.ipynb","provenance":[{"file_id":"1vfVY97GTxVR-FK2pzG4t9bVpvKyRY2BV","timestamp":1583464102669},{"file_id":"1A1btRTjsjrWv848DJrEaeIbfeTaayeIQ","timestamp":1583331707712}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"kDk6zDcjRTgd","colab_type":"code","outputId":"153a4970-b533-4d86-c952-4194f8819ff7","executionInfo":{"status":"ok","timestamp":1583464118869,"user_tz":300,"elapsed":3591,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"04069451015857955148"}},"colab":{"base_uri":"https://localhost:8080/","height":79}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import Adam\n","from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.applications import DenseNet121, DenseNet169\n","\n","import gc\n","import cv2\n","import numpy as np \n","import pandas as pd \n","import random \n","import os\n","from tqdm.auto import tqdm\n","import pickle\n","import time\n","import albumentations\n","from albumentations.core.transforms_interface import DualTransform, ImageOnlyTransform\n","from albumentations.augmentations import functional as F\n","\n","from sklearn.model_selection import train_test_split"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"42H11KPuU_9C","colab_type":"code","outputId":"a1d16c14-2ce5-4eb8-a6ed-354cefe2d70f","executionInfo":{"status":"ok","timestamp":1583460997762,"user_tz":300,"elapsed":6200,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"04069451015857955148"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZAzpt39DUuQy","colab_type":"text"},"source":["# Load Data & Aug"]},{"cell_type":"code","metadata":{"id":"qVZhJXPz_L3v","colab_type":"code","colab":{}},"source":["'''96x96'''\n","'''Load image data and labels'''\n","\n","tot_file_0 = open(\"/content/drive/My Drive/Untitled folder/bengaliai-cv19/Resized/train_0_96x96\", 'rb')\n","tot_data_0 = pickle.load(tot_file_0)\n","tot_file_1 = open(\"/content/drive/My Drive/Untitled folder/bengaliai-cv19/Resized/train_1_96x96\", 'rb')\n","tot_data_1 = pickle.load(tot_file_1)\n","tot_file_2 = open(\"/content/drive/My Drive/Untitled folder/bengaliai-cv19/Resized/train_2_96x96\", 'rb')\n","tot_data_2 = pickle.load(tot_file_2)\n","tot_file_3 = open(\"/content/drive/My Drive/Untitled folder/bengaliai-cv19/Resized/train_3_96x96\", 'rb')\n","tot_data_3 = pickle.load(tot_file_3)\n","tot_data = pd.concat([pd.DataFrame(tot_data_0), pd.DataFrame(tot_data_1), pd.DataFrame(tot_data_2), pd.DataFrame(tot_data_3)],ignore_index=True)\n","# print(tot_data.shape)\n","T = tot_data.shape[0]\n","\n","del tot_file_0\n","del tot_file_1\n","del tot_file_2\n","del tot_file_3\n","\n","tot_csv = pd.read_csv(\"/content/drive/My Drive/Untitled folder/bengaliai-cv19/train.csv\")\n","tot_labels = [tot_csv.loc[:T, ['grapheme_root']], \n","              tot_csv.loc[:T, ['vowel_diacritic']], \n","              tot_csv.loc[:T, ['consonant_diacritic']]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vAeXvsyzVZuM","colab_type":"code","colab":{}},"source":["'''Load image data and labels'''\n","\n","tot_file_0 = open(\"/content/drive/My Drive/Untitled folder/bengaliai-cv19/Resized/Resized/train_0_resized\", 'rb')\n","tot_data_0 = pickle.load(tot_file_0)\n","tot_file_1 = open(\"/content/drive/My Drive/Untitled folder/bengaliai-cv19/Resized/Resized/train_1_resized\", 'rb')\n","tot_data_1 = pickle.load(tot_file_1)\n","tot_file_2 = open(\"/content/drive/My Drive/Untitled folder/bengaliai-cv19/Resized/Resized/train_2_resized\", 'rb')\n","tot_data_2 = pickle.load(tot_file_2)\n","tot_file_3 = open(\"/content/drive/My Drive/Untitled folder/bengaliai-cv19/Resized/Resized/train_3_resized\", 'rb')\n","tot_data_3 = pickle.load(tot_file_3)\n","tot_data = pd.concat([tot_data_0, tot_data_1, tot_data_2, tot_data_3],ignore_index=True)\n","# print(tot_data.shape)\n","T = tot_data.shape[0]\n","\n","del tot_file_0\n","del tot_file_1\n","del tot_file_2\n","del tot_file_3\n","\n","tot_csv = pd.read_csv(\"/content/drive/My Drive/Untitled folder/bengaliai-cv19/train.csv\")\n","tot_labels = [tot_csv.loc[:T, ['grapheme_root']], \n","              tot_csv.loc[:T, ['vowel_diacritic']], \n","              tot_csv.loc[:T, ['consonant_diacritic']]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwUv1FhFVe3p","colab_type":"code","colab":{}},"source":["# Loading the data, run once every load\n","\n","\"\"\"\n","7 consonant\n","11 vowel\n","168 root\n","\"\"\"\n","\n","SIZE=96\n","\n","def returndata(train_size, T, tot_data, tot_labels, tot_csv, SIZE):\n","    train = tot_data.loc[:train_size-1, ]\n","    \n","    train = np.reshape(train.values, (train.shape[0], SIZE, SIZE, 1))\n","\n","    root_train_labels, vowel_train_labels, consonant_train_labels = (tot_labels[0][:train_size], \n","                                       tot_labels[1][:train_size], \n","                                       tot_labels[2][:train_size])\n","    tot_csv = tot_csv[:train_size]\n","\n","    train, test, root_train_labels, root_test_labels, vowel_train_labels, vowel_test_labels, consonant_train_labels, consonant_test_labels, train_csv, test_csv = train_test_split(train, root_train_labels, vowel_train_labels, consonant_train_labels, tot_csv, test_size=1/6, random_state=666)\n","    test, valid, root_test_labels, root_valid_labels, vowel_test_labels, vowel_valid_labels, consonant_test_labels, consonant_valid_labels, test_csv, valid_csv = train_test_split(test, root_test_labels, vowel_test_labels, consonant_test_labels, test_csv, test_size=0.5, random_state=666)\n","\n","    return ((train, valid, test), \n","            (root_train_labels, root_valid_labels, root_test_labels), \n","            (vowel_train_labels, vowel_valid_labels, vowel_test_labels), \n","            (consonant_train_labels, consonant_valid_labels, consonant_test_labels),\n","            (tot_data, tot_labels), (train_csv, valid_csv, test_csv))\n","\n","TOT_DATA = returndata(T, T, tot_data, tot_labels, tot_csv, SIZE)\n","\n","((train_data, valid_data, test_data), \n","(root_train_labels, root_valid_labels, root_test_labels), \n","(vowel_train_labels, vowel_valid_labels, vowel_test_labels), \n","(consonant_train_labels, consonant_valid_labels, consonant_test_labels),\n","(tot_data, tot_labels), (train_csv, valid_csv, test_csv)) = TOT_DATA"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cMq7S6mfVjoG","colab_type":"code","colab":{}},"source":["class MulticlassGenerator(keras.preprocessing.image.ImageDataGenerator):\n","\n","    def flow(self, X, Y,\n","             batch_size = 64,\n","             shuffle = True):\n","        \n","        targets = None\n","        target_lengths = {}\n","        ordered_outputs = []\n","        for output, target in Y.items():\n","            if targets is None:\n","                targets = target\n","            else:\n","                targets = np.concatenate((targets, target), axis=1)\n","            ordered_outputs.append(output)\n","\n","\n","        for flowx, flowy in super().flow(X, targets, \n","                                         batch_size = batch_size,\n","                                         shuffle = shuffle):\n","            target_dict = {}\n","            for i, output in enumerate(ordered_outputs):\n","                target_dict[output] = flowy[:, i]\n","\n","            yield flowx, target_dict\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aI612ajDVQ-I","colab_type":"text"},"source":["## Aug"]},{"cell_type":"code","metadata":{"id":"ih1Pr00tU9p-","colab_type":"code","colab":{}},"source":["class GridMask(DualTransform):\n","    \"\"\"GridMask augmentation for image classification and object detection.\n","\n","    Args:\n","        num_grid (int): number of grid in a row or column.\n","        fill_value (int, float, lisf of int, list of float): value for dropped pixels.\n","        rotate ((int, int) or int): range from which a random angle is picked. If rotate is a single int\n","            an angle is picked from (-rotate, rotate). Default: (-90, 90)\n","        mode (int):\n","            0 - cropout a quarter of the square of each grid (left top)\n","            1 - reserve a quarter of the square of each grid (left top)\n","            2 - cropout 2 quarter of the square of each grid (left top & right bottom)\n","\n","    Targets:\n","        image, mask\n","\n","    Image types:\n","        uint8, float32\n","\n","    Reference:\n","    |  https://arxiv.org/abs/2001.04086\n","    |  https://github.com/akuxcw/GridMask\n","    \"\"\"\n","\n","    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):\n","        super(GridMask, self).__init__(always_apply, p)\n","        if isinstance(num_grid, int):\n","            num_grid = (num_grid, num_grid)\n","        if isinstance(rotate, int):\n","            rotate = (-rotate, rotate)\n","        self.num_grid = num_grid\n","        self.fill_value = fill_value\n","        self.rotate = rotate\n","        self.mode = mode\n","        self.masks = None\n","        self.rand_h_max = []\n","        self.rand_w_max = []\n","\n","    def init_masks(self, height, width):\n","        if self.masks is None:\n","            self.masks = []\n","            n_masks = self.num_grid[1] - self.num_grid[0] + 1\n","            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):\n","                grid_h = height / n_g\n","                grid_w = width / n_g\n","                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)\n","                for i in range(n_g + 1):\n","                    for j in range(n_g + 1):\n","                        this_mask[\n","                             int(i * grid_h) : int(i * grid_h + grid_h / 2),\n","                             int(j * grid_w) : int(j * grid_w + grid_w / 2)\n","                        ] = self.fill_value\n","                        if self.mode == 2:\n","                            this_mask[\n","                                 int(i * grid_h + grid_h / 2) : int(i * grid_h + grid_h),\n","                                 int(j * grid_w + grid_w / 2) : int(j * grid_w + grid_w)\n","                            ] = self.fill_value\n","                \n","                if self.mode == 1:\n","                    this_mask = 1 - this_mask\n","\n","                self.masks.append(this_mask)\n","                self.rand_h_max.append(grid_h)\n","                self.rand_w_max.append(grid_w)\n","\n","    def apply(self, image, mask, rand_h, rand_w, angle, **params):\n","        h, w = image.shape[:2]\n","        mask = F.rotate(mask, angle) if self.rotate[1] > 0 else mask\n","        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask\n","        image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)\n","        return image\n","\n","    def get_params_dependent_on_targets(self, params):\n","        img = params['image']\n","        height, width = img.shape[:2]\n","        self.init_masks(height, width)\n","\n","        mid = np.random.randint(len(self.masks))\n","        mask = self.masks[mid]\n","        rand_h = np.random.randint(self.rand_h_max[mid])\n","        rand_w = np.random.randint(self.rand_w_max[mid])\n","        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0\n","\n","        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}\n","\n","    @property\n","    def targets_as_params(self):\n","        return ['image']\n","\n","    def get_transform_init_args_names(self):\n","        return ('num_grid', 'fill_value', 'rotate', 'mode')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tk1N1vpWVYAw","colab_type":"text"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"yO7h8RzMTL8P","colab_type":"code","colab":{}},"source":["from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Dense, BatchNormalization, Dropout\n","\n","SIZE = 96\n","\n","keras.backend.clear_session()\n","\n","densenet = DenseNet121(weights='imagenet', include_top=False)\n","\n","inputs = keras.Input(shape=(SIZE, SIZE, 1))\n","model = Conv2D(3, (3, 3), padding=\"same\")(inputs)\n","\n","model = densenet(model)\n","\n","model = GlobalAveragePooling2D()(model)\n","model = BatchNormalization()(model)\n","model = Dropout(0.3)(model)\n","dense = Dense(1024, activation=\"relu\")(model)\n","# dense = Dropout(0.3)(dense)\n","# dense = Dense(512, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001))(dense)\n","\n","root = keras.layers.Dense(168, name='root', activation=\"softmax\")(dense)\n","vowel = keras.layers.Dense(11, name='vowel', activation=\"softmax\")(dense)\n","consonant = keras.layers.Dense(7, name='consonant', activation=\"softmax\")(dense)\n","\n","model = keras.models.Model(inputs=inputs, outputs=[root, vowel, consonant])\n","\n","# sgd = keras.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n","class_weight = {'root':4, 'vowel':3, 'consonant':3}\n","\n","model.compile(optimizer=\"adam\", loss={'root': 'sparse_categorical_crossentropy',\n","                    'vowel': 'sparse_categorical_crossentropy',\n","                    'consonant': 'sparse_categorical_crossentropy'},\n","              metrics={'root': 'accuracy',\n","                       'vowel': 'accuracy',\n","                       'consonant': 'accuracy'},\n","              loss_weights=class_weight)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"298Jan9FUrgP","colab_type":"code","colab":{}},"source":["transforms_train = albumentations.Compose([\n","    GridMask(num_grid=3, rotate=8, p=1),\n","])\n","\n","def transforms(image):\n","  image = cv2.resize(image, (SIZE, SIZE))\n","  temp = transforms_train(image=image)\n","  image = temp['image']\n","  return image[:,:,np.newaxis]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0uwul77DaJCY","colab_type":"code","colab":{}},"source":["batch_size = 64\n","\n","lr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor = 'val_root_loss',\n","                             patience = 2,\n","                             factor = 0.5,\n","                             min_lr = 1e-5,\n","                             verbose = 1)\n","\n","earlystop = keras.callbacks.EarlyStopping(monitor=\"val_root_loss\", patience=6, restore_best_weights=True)\n","\n","checkpoint = keras.callbacks.ModelCheckpoint(\"/content/drive/My Drive/Colab Notebooks/bengaliai-cv19/saved_models/densenet_3.h5\", \n","                                 monitor = 'val_root_loss', \n","                                 verbose = 0, save_best_only=True, \n","                                 mode = 'min',\n","                                 save_weights_only = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gssnf0A50Uuv","colab_type":"code","colab":{}},"source":["del tot_data_0\n","del tot_data_1\n","del tot_data_2\n","del tot_data_3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qkn5CCOMaKvX","colab_type":"code","outputId":"f7ab7284-1772-4848-942a-cf4f6d6af37e","executionInfo":{"status":"ok","timestamp":1583446978055,"user_tz":300,"elapsed":123775,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"04069451015857955148"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_datagen = MulticlassGenerator(\n","    rescale=1./255, \n","    rotation_range=8,\n","    shear_range=2,\n","    width_shift_range=0.15,\n","    height_shift_range=0.15,\n","    preprocessing_function=transforms,\n",")\n","\n","datagen = MulticlassGenerator(rescale=1./255)\n","\n","train_datagen.fit(train_data, augment=True)\n","\n","train_gen = train_datagen.flow(train_data, {'root':root_train_labels, 'vowel':vowel_train_labels, 'consonant':consonant_train_labels}, \n","                         batch_size=batch_size, shuffle=True)\n","valid_gen = datagen.flow(valid_data, {'root':root_valid_labels,'vowel':vowel_valid_labels,'consonant':consonant_valid_labels}, \n","                         batch_size=batch_size, shuffle=False)\n","\n","gc.collect()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["263"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"1EkKNoBiWrbs","colab_type":"code","outputId":"001cb101-d54c-42af-f2db-d603da3c84ce","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Training Loop\n","train_range = 4\n","SIZE = 128\n","seed = 6666\n","\n","histories = []\n","\n","tot_csv = pd.read_csv(\"/content/drive/My Drive/Untitled folder/bengaliai-cv19/train.csv\")\n","tot_labels = [tot_csv.loc[:, ['grapheme_root']], \n","              tot_csv.loc[:, ['vowel_diacritic']], \n","              tot_csv.loc[:, ['consonant_diacritic']]]\n","\n","for i in range(train_range):\n","  train_file = pickle.load(open(f\"/content/drive/My Drive/Untitled folder/bengaliai-cv19/Resized/train_{i}_{SIZE}x{SIZE}\", 'rb'))\n","  T = train_file.shape[0]\n","  train_data = np.reshape(train_file, (train_file.shape[0], SIZE, SIZE, 1))\n","  del train_file\n","  root_train_labels, vowel_train_labels, consonant_train_labels = (tot_labels[0][50210*i:50210*(i+1)], \n","                                    tot_labels[1][50210*i:50210*(i+1)], \n","                                    tot_labels[2][50210*i:50210*(i+1)])\n","  train_data, test_data, root_train_labels, root_test_labels, vowel_train_labels, vowel_test_labels, consonant_train_labels, consonant_test_labels = train_test_split(train_data, root_train_labels, vowel_train_labels, consonant_train_labels, test_size=0.1, random_state=seed)\n","  test_data, valid_data, root_test_labels, root_valid_labels, vowel_test_labels, vowel_valid_labels, consonant_test_labels, consonant_valid_labels = train_test_split(test_data, root_test_labels, vowel_test_labels, consonant_test_labels, test_size=0.5, random_state=seed)\n","\n","  train_datagen = MulticlassGenerator(\n","      rescale=1./255, \n","      rotation_range=8,\n","      shear_range=2,\n","      width_shift_range=0.15,\n","      height_shift_range=0.15,\n","      preprocessing_function=transforms\n","  )\n","\n","  datagen = MulticlassGenerator(rescale=1./255)\n","\n","  train_datagen.fit(train_data)\n","\n","  train_gen = train_datagen.flow(train_data, {'root':root_train_labels, 'vowel':vowel_train_labels, 'consonant':consonant_train_labels}, \n","                         batch_size=batch_size, shuffle=True)\n","  valid_gen = datagen.flow(valid_data, {'root':root_valid_labels,'vowel':vowel_valid_labels,'consonant':consonant_valid_labels}, \n","                         batch_size=batch_size, shuffle=False)\n","\n","  history = model.fit(train_gen, epochs=60, verbose=1,\n","          validation_data=valid_gen,\n","          validation_steps=valid_data.shape[0] // (batch_size),\n","          steps_per_epoch=train_data.shape[0] // (batch_size), \n","          callbacks=[lr_scheduler, earlystop \n","                     ,checkpoint\n","                     ]\n","          )\n","  del train_data\n","  del test_data\n","  del valid_data\n","  \n","  histories.append(history)\n","\n","\n","  gc.collect()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/60\n","705/706 [============================>.] - ETA: 0s - loss: 13.1297 - root_loss: 2.3114 - vowel_loss: 0.7500 - consonant_loss: 0.5448 - root_acc: 0.4344 - vowel_acc: 0.7483 - consonant_acc: 0.8210Epoch 1/60\n","706/706 [==============================] - 175s 248ms/step - loss: 13.1189 - root_loss: 2.3095 - vowel_loss: 0.7493 - consonant_loss: 0.5443 - root_acc: 0.4348 - vowel_acc: 0.7486 - consonant_acc: 0.8212 - val_loss: 6.5598 - val_root_loss: 1.2414 - val_vowel_loss: 0.2880 - val_consonant_loss: 0.2434 - val_root_acc: 0.6671 - val_vowel_acc: 0.9075 - val_consonant_acc: 0.9191\n","Epoch 2/60\n","705/706 [============================>.] - ETA: 0s - loss: 5.7294 - root_loss: 0.9421 - vowel_loss: 0.3709 - consonant_loss: 0.2828 - root_acc: 0.7321 - vowel_acc: 0.8801 - consonant_acc: 0.9076Epoch 1/60\n","706/706 [==============================] - 131s 186ms/step - loss: 5.7271 - root_loss: 0.9416 - vowel_loss: 0.3708 - consonant_loss: 0.2828 - root_acc: 0.7323 - vowel_acc: 0.8801 - consonant_acc: 0.9076 - val_loss: 4.3653 - val_root_loss: 0.7677 - val_vowel_loss: 0.2664 - val_consonant_loss: 0.1652 - val_root_acc: 0.7879 - val_vowel_acc: 0.9174 - val_consonant_acc: 0.9469\n","Epoch 3/60\n","705/706 [============================>.] - ETA: 0s - loss: 4.6013 - root_loss: 0.7400 - vowel_loss: 0.3087 - consonant_loss: 0.2385 - root_acc: 0.7880 - vowel_acc: 0.9023 - consonant_acc: 0.9228Epoch 1/60\n","706/706 [==============================] - 131s 185ms/step - loss: 4.6017 - root_loss: 0.7403 - vowel_loss: 0.3086 - consonant_loss: 0.2383 - root_acc: 0.7880 - vowel_acc: 0.9023 - consonant_acc: 0.9229 - val_loss: 3.4102 - val_root_loss: 0.6084 - val_vowel_loss: 0.1744 - val_consonant_loss: 0.1512 - val_root_acc: 0.8255 - val_vowel_acc: 0.9477 - val_consonant_acc: 0.9522\n","Epoch 4/60\n","705/706 [============================>.] - ETA: 0s - loss: 4.0069 - root_loss: 0.6347 - vowel_loss: 0.2790 - consonant_loss: 0.2104 - root_acc: 0.8162 - vowel_acc: 0.9132 - consonant_acc: 0.9327Epoch 1/60\n","706/706 [==============================] - 130s 185ms/step - loss: 4.0068 - root_loss: 0.6346 - vowel_loss: 0.2790 - consonant_loss: 0.2104 - root_acc: 0.8162 - vowel_acc: 0.9132 - consonant_acc: 0.9327 - val_loss: 2.9816 - val_root_loss: 0.5084 - val_vowel_loss: 0.1614 - val_consonant_loss: 0.1546 - val_root_acc: 0.8586 - val_vowel_acc: 0.9473 - val_consonant_acc: 0.9485\n","Epoch 5/60\n","705/706 [============================>.] - ETA: 0s - loss: 3.7531 - root_loss: 0.5875 - vowel_loss: 0.2664 - consonant_loss: 0.2013 - root_acc: 0.8315 - vowel_acc: 0.9171 - consonant_acc: 0.9349Epoch 1/60\n","706/706 [==============================] - 131s 185ms/step - loss: 3.7514 - root_loss: 0.5874 - vowel_loss: 0.2662 - consonant_loss: 0.2011 - root_acc: 0.8316 - vowel_acc: 0.9171 - consonant_acc: 0.9349 - val_loss: 2.3935 - val_root_loss: 0.4176 - val_vowel_loss: 0.1415 - val_consonant_loss: 0.0996 - val_root_acc: 0.8826 - val_vowel_acc: 0.9519 - val_consonant_acc: 0.9655\n","Epoch 6/60\n","705/706 [============================>.] - ETA: 0s - loss: 3.4815 - root_loss: 0.5441 - vowel_loss: 0.2446 - consonant_loss: 0.1905 - root_acc: 0.8448 - vowel_acc: 0.9253 - consonant_acc: 0.9391Epoch 1/60\n","706/706 [==============================] - 129s 183ms/step - loss: 3.4814 - root_loss: 0.5440 - vowel_loss: 0.2446 - consonant_loss: 0.1905 - root_acc: 0.8448 - vowel_acc: 0.9253 - consonant_acc: 0.9391 - val_loss: 2.7180 - val_root_loss: 0.4747 - val_vowel_loss: 0.1630 - val_consonant_loss: 0.1101 - val_root_acc: 0.8647 - val_vowel_acc: 0.9473 - val_consonant_acc: 0.9649\n","Epoch 7/60\n","705/706 [============================>.] - ETA: 0s - loss: 3.1995 - root_loss: 0.4974 - vowel_loss: 0.2265 - consonant_loss: 0.1768 - root_acc: 0.8562 - vowel_acc: 0.9303 - consonant_acc: 0.9447Epoch 1/60\n","706/706 [==============================] - 131s 185ms/step - loss: 3.2007 - root_loss: 0.4975 - vowel_loss: 0.2268 - consonant_loss: 0.1768 - root_acc: 0.8561 - vowel_acc: 0.9302 - consonant_acc: 0.9448 - val_loss: 2.2842 - val_root_loss: 0.3925 - val_vowel_loss: 0.1397 - val_consonant_loss: 0.0984 - val_root_acc: 0.8917 - val_vowel_acc: 0.9632 - val_consonant_acc: 0.9661\n","Epoch 8/60\n","705/706 [============================>.] - ETA: 0s - loss: 3.0197 - root_loss: 0.4656 - vowel_loss: 0.2202 - consonant_loss: 0.1655 - root_acc: 0.8647 - vowel_acc: 0.9331 - consonant_acc: 0.9460Epoch 1/60\n","706/706 [==============================] - 131s 185ms/step - loss: 3.0194 - root_loss: 0.4656 - vowel_loss: 0.2202 - consonant_loss: 0.1655 - root_acc: 0.8646 - vowel_acc: 0.9331 - consonant_acc: 0.9460 - val_loss: 1.9295 - val_root_loss: 0.3210 - val_vowel_loss: 0.1310 - val_consonant_loss: 0.0842 - val_root_acc: 0.9097 - val_vowel_acc: 0.9632 - val_consonant_acc: 0.9763\n","Epoch 9/60\n","705/706 [============================>.] - ETA: 0s - loss: 2.8116 - root_loss: 0.4285 - vowel_loss: 0.2054 - consonant_loss: 0.1605 - root_acc: 0.8737 - vowel_acc: 0.9353 - consonant_acc: 0.9480Epoch 1/60\n","706/706 [==============================] - 130s 184ms/step - loss: 2.8120 - root_loss: 0.4284 - vowel_loss: 0.2054 - consonant_loss: 0.1607 - root_acc: 0.8737 - vowel_acc: 0.9353 - consonant_acc: 0.9480 - val_loss: 1.9298 - val_root_loss: 0.3471 - val_vowel_loss: 0.1061 - val_consonant_loss: 0.0743 - val_root_acc: 0.9111 - val_vowel_acc: 0.9663 - val_consonant_acc: 0.9792\n","Epoch 10/60\n","705/706 [============================>.] - ETA: 0s - loss: 2.7556 - root_loss: 0.4223 - vowel_loss: 0.2016 - consonant_loss: 0.1539 - root_acc: 0.8763 - vowel_acc: 0.9380 - consonant_acc: 0.9518Epoch 1/60\n"," 39/706 [>.............................] - ETA: 36s - loss: 1.9653 - root_loss: 0.3412 - vowel_loss: 0.1146 - consonant_loss: 0.0856 - root_acc: 0.9044 - vowel_acc: 0.9657 - consonant_acc: 0.9718\n","Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","706/706 [==============================] - 132s 188ms/step - loss: 2.7563 - root_loss: 0.4224 - vowel_loss: 0.2016 - consonant_loss: 0.1539 - root_acc: 0.8762 - vowel_acc: 0.9380 - consonant_acc: 0.9519 - val_loss: 1.9653 - val_root_loss: 0.3412 - val_vowel_loss: 0.1146 - val_consonant_loss: 0.0856 - val_root_acc: 0.9044 - val_vowel_acc: 0.9657 - val_consonant_acc: 0.9718\n","Epoch 11/60\n","705/706 [============================>.] - ETA: 0s - loss: 1.8607 - root_loss: 0.2701 - vowel_loss: 0.1480 - consonant_loss: 0.1121 - root_acc: 0.9178 - vowel_acc: 0.9540 - consonant_acc: 0.9643Epoch 1/60\n","706/706 [==============================] - 132s 187ms/step - loss: 1.8616 - root_loss: 0.2703 - vowel_loss: 0.1481 - consonant_loss: 0.1121 - root_acc: 0.9177 - vowel_acc: 0.9540 - consonant_acc: 0.9643 - val_loss: 1.3220 - val_root_loss: 0.2332 - val_vowel_loss: 0.0752 - val_consonant_loss: 0.0546 - val_root_acc: 0.9371 - val_vowel_acc: 0.9779 - val_consonant_acc: 0.9845\n","Epoch 12/60\n","705/706 [============================>.] - ETA: 0s - loss: 1.7206 - root_loss: 0.2462 - vowel_loss: 0.1375 - consonant_loss: 0.1078 - root_acc: 0.9248 - vowel_acc: 0.9559 - consonant_acc: 0.9662Epoch 1/60\n","706/706 [==============================] - 131s 186ms/step - loss: 1.7217 - root_loss: 0.2464 - vowel_loss: 0.1375 - consonant_loss: 0.1078 - root_acc: 0.9248 - vowel_acc: 0.9559 - consonant_acc: 0.9662 - val_loss: 1.5381 - val_root_loss: 0.2477 - val_vowel_loss: 0.1237 - val_consonant_loss: 0.0587 - val_root_acc: 0.9350 - val_vowel_acc: 0.9616 - val_consonant_acc: 0.9824\n","Epoch 13/60\n","705/706 [============================>.] - ETA: 0s - loss: 1.6347 - root_loss: 0.2331 - vowel_loss: 0.1330 - consonant_loss: 0.1011 - root_acc: 0.9279 - vowel_acc: 0.9591 - consonant_acc: 0.9674Epoch 1/60\n"," 39/706 [>.............................] - ETA: 36s - loss: 1.4729 - root_loss: 0.2635 - vowel_loss: 0.0812 - consonant_loss: 0.0584 - root_acc: 0.9327 - vowel_acc: 0.9792 - consonant_acc: 0.9792\n","Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","706/706 [==============================] - 131s 185ms/step - loss: 1.6348 - root_loss: 0.2331 - vowel_loss: 0.1329 - consonant_loss: 0.1012 - root_acc: 0.9278 - vowel_acc: 0.9592 - consonant_acc: 0.9673 - val_loss: 1.4729 - val_root_loss: 0.2635 - val_vowel_loss: 0.0812 - val_consonant_loss: 0.0584 - val_root_acc: 0.9327 - val_vowel_acc: 0.9792 - val_consonant_acc: 0.9792\n","Epoch 14/60\n","705/706 [============================>.] - ETA: 0s - loss: 1.2379 - root_loss: 0.1693 - vowel_loss: 0.1041 - consonant_loss: 0.0829 - root_acc: 0.9464 - vowel_acc: 0.9677 - consonant_acc: 0.9733Epoch 1/60\n","706/706 [==============================] - 131s 185ms/step - loss: 1.2379 - root_loss: 0.1693 - vowel_loss: 0.1040 - consonant_loss: 0.0829 - root_acc: 0.9463 - vowel_acc: 0.9678 - consonant_acc: 0.9733 - val_loss: 1.2158 - val_root_loss: 0.2102 - val_vowel_loss: 0.0767 - val_consonant_loss: 0.0483 - val_root_acc: 0.9440 - val_vowel_acc: 0.9812 - val_consonant_acc: 0.9861\n","Epoch 15/60\n","705/706 [============================>.] - ETA: 0s - loss: 1.1165 - root_loss: 0.1502 - vowel_loss: 0.0957 - consonant_loss: 0.0761 - root_acc: 0.9519 - vowel_acc: 0.9694 - consonant_acc: 0.9761Epoch 1/60\n","706/706 [==============================] - 131s 185ms/step - loss: 1.1172 - root_loss: 0.1503 - vowel_loss: 0.0958 - consonant_loss: 0.0761 - root_acc: 0.9518 - vowel_acc: 0.9694 - consonant_acc: 0.9761 - val_loss: 1.1338 - val_root_loss: 0.2051 - val_vowel_loss: 0.0596 - val_consonant_loss: 0.0448 - val_root_acc: 0.9481 - val_vowel_acc: 0.9808 - val_consonant_acc: 0.9853\n","Epoch 16/60\n","705/706 [============================>.] - ETA: 0s - loss: 1.1197 - root_loss: 0.1513 - vowel_loss: 0.0957 - consonant_loss: 0.0758 - root_acc: 0.9529 - vowel_acc: 0.9703 - consonant_acc: 0.9760Epoch 1/60\n","706/706 [==============================] - 130s 184ms/step - loss: 1.1189 - root_loss: 0.1512 - vowel_loss: 0.0957 - consonant_loss: 0.0757 - root_acc: 0.9529 - vowel_acc: 0.9703 - consonant_acc: 0.9760 - val_loss: 1.1017 - val_root_loss: 0.1960 - val_vowel_loss: 0.0667 - val_consonant_loss: 0.0392 - val_root_acc: 0.9522 - val_vowel_acc: 0.9796 - val_consonant_acc: 0.9910\n","Epoch 17/60\n","705/706 [============================>.] - ETA: 0s - loss: 1.0473 - root_loss: 0.1398 - vowel_loss: 0.0904 - consonant_loss: 0.0724 - root_acc: 0.9559 - vowel_acc: 0.9713 - consonant_acc: 0.9770Epoch 1/60\n","706/706 [==============================] - 129s 183ms/step - loss: 1.0472 - root_loss: 0.1398 - vowel_loss: 0.0904 - consonant_loss: 0.0723 - root_acc: 0.9559 - vowel_acc: 0.9713 - consonant_acc: 0.9771 - val_loss: 1.2095 - val_root_loss: 0.2156 - val_vowel_loss: 0.0647 - val_consonant_loss: 0.0511 - val_root_acc: 0.9455 - val_vowel_acc: 0.9824 - val_consonant_acc: 0.9836\n","Epoch 18/60\n","705/706 [============================>.] - ETA: 0s - loss: 0.9947 - root_loss: 0.1300 - vowel_loss: 0.0911 - consonant_loss: 0.0671 - root_acc: 0.9585 - vowel_acc: 0.9711 - consonant_acc: 0.9785Epoch 1/60\n"," 39/706 [>.............................] - ETA: 35s - loss: 1.2315 - root_loss: 0.2036 - vowel_loss: 0.0948 - consonant_loss: 0.0442 - root_acc: 0.9501 - vowel_acc: 0.9714 - consonant_acc: 0.9857\n","Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","706/706 [==============================] - 129s 183ms/step - loss: 0.9941 - root_loss: 0.1299 - vowel_loss: 0.0911 - consonant_loss: 0.0670 - root_acc: 0.9586 - vowel_acc: 0.9710 - consonant_acc: 0.9785 - val_loss: 1.2315 - val_root_loss: 0.2036 - val_vowel_loss: 0.0948 - val_consonant_loss: 0.0442 - val_root_acc: 0.9501 - val_vowel_acc: 0.9714 - val_consonant_acc: 0.9857\n","Epoch 19/60\n","705/706 [============================>.] - ETA: 0s - loss: 0.8351 - root_loss: 0.1089 - vowel_loss: 0.0745 - consonant_loss: 0.0586 - root_acc: 0.9650 - vowel_acc: 0.9762 - consonant_acc: 0.9808Epoch 1/60\n","706/706 [==============================] - 129s 183ms/step - loss: 0.8355 - root_loss: 0.1090 - vowel_loss: 0.0745 - consonant_loss: 0.0586 - root_acc: 0.9650 - vowel_acc: 0.9762 - consonant_acc: 0.9808 - val_loss: 1.1124 - val_root_loss: 0.1987 - val_vowel_loss: 0.0648 - val_consonant_loss: 0.0411 - val_root_acc: 0.9538 - val_vowel_acc: 0.9828 - val_consonant_acc: 0.9849\n","Epoch 20/60\n","705/706 [============================>.] - ETA: 0s - loss: 0.7667 - root_loss: 0.0976 - vowel_loss: 0.0685 - consonant_loss: 0.0570 - root_acc: 0.9680 - vowel_acc: 0.9778 - consonant_acc: 0.9815Epoch 1/60\n"," 39/706 [>.............................] - ETA: 35s - loss: 1.1091 - root_loss: 0.1985 - vowel_loss: 0.0642 - consonant_loss: 0.0408 - root_acc: 0.9538 - vowel_acc: 0.9849 - consonant_acc: 0.9898\n","Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","706/706 [==============================] - 129s 183ms/step - loss: 0.7674 - root_loss: 0.0976 - vowel_loss: 0.0684 - consonant_loss: 0.0572 - root_acc: 0.9680 - vowel_acc: 0.9778 - consonant_acc: 0.9815 - val_loss: 1.1091 - val_root_loss: 0.1985 - val_vowel_loss: 0.0642 - val_consonant_loss: 0.0408 - val_root_acc: 0.9538 - val_vowel_acc: 0.9849 - val_consonant_acc: 0.9898\n","Epoch 21/60\n","705/706 [============================>.] - ETA: 0s - loss: 0.7254 - root_loss: 0.0912 - vowel_loss: 0.0667 - consonant_loss: 0.0535 - root_acc: 0.9711 - vowel_acc: 0.9779 - consonant_acc: 0.9821Epoch 1/60\n","706/706 [==============================] - 131s 185ms/step - loss: 0.7254 - root_loss: 0.0912 - vowel_loss: 0.0667 - consonant_loss: 0.0535 - root_acc: 0.9711 - vowel_acc: 0.9779 - consonant_acc: 0.9821 - val_loss: 1.0829 - val_root_loss: 0.1947 - val_vowel_loss: 0.0590 - val_consonant_loss: 0.0423 - val_root_acc: 0.9555 - val_vowel_acc: 0.9860 - val_consonant_acc: 0.9880\n","Epoch 22/60\n","705/706 [============================>.] - ETA: 0s - loss: 0.6567 - root_loss: 0.0815 - vowel_loss: 0.0616 - consonant_loss: 0.0486 - root_acc: 0.9742 - vowel_acc: 0.9798 - consonant_acc: 0.9838Epoch 1/60\n","706/706 [==============================] - 131s 185ms/step - loss: 0.6569 - root_loss: 0.0815 - vowel_loss: 0.0616 - consonant_loss: 0.0487 - root_acc: 0.9742 - vowel_acc: 0.9798 - consonant_acc: 0.9837 - val_loss: 1.0909 - val_root_loss: 0.1909 - val_vowel_loss: 0.0637 - val_consonant_loss: 0.0454 - val_root_acc: 0.9559 - val_vowel_acc: 0.9828 - val_consonant_acc: 0.9869\n","Epoch 23/60\n","104/706 [===>..........................] - ETA: 1:48 - loss: 0.6327 - root_loss: 0.0756 - vowel_loss: 0.0664 - consonant_loss: 0.0437 - root_acc: 0.9735 - vowel_acc: 0.9786 - consonant_acc: 0.9859"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6kwVwU7YaMp0","colab_type":"code","outputId":"6954f833-d0f7-49ee-c368-cffc82e08c80","executionInfo":{"status":"error","timestamp":1583456218247,"user_tz":300,"elapsed":5071209,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"04069451015857955148"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# earlystop = keras.callbacks.EarlyStopping(monitor=\"val_root_loss\", patience=3, restore_best_weights=True)\n","# model.load_weights(\"/content/drive/My Drive/Colab Notebooks/bengaliai-cv19/saved_models/densenet_3.h5\")\n","# load = keras.models.load_model(\"/content/drive/My Drive/Colab Notebooks/bengaliai-cv19/saved_models/densenet_aug_1.h5\")\n","\n","history_res = model.fit(train_gen, epochs=60, verbose=1,\n","          validation_data=valid_gen,\n","          validation_steps=valid_data.shape[0] // (batch_size),\n","          steps_per_epoch=train_data.shape[0] // (batch_size), \n","          callbacks=[lr_scheduler, earlystop \n","                     ,checkpoint\n","                     ]\n","          )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 8.4957 - root_loss: 1.4663 - vowel_loss: 0.5028 - consonant_loss: 0.3741 - root_acc: 0.6231 - vowel_acc: 0.8352 - consonant_acc: 0.8777Epoch 1/60\n","1307/1307 [==============================] - 331s 254ms/step - loss: 8.4933 - root_loss: 1.4659 - vowel_loss: 0.5026 - consonant_loss: 0.3740 - root_acc: 0.6232 - vowel_acc: 0.8352 - consonant_acc: 0.8778 - val_loss: 2.9166 - val_root_loss: 0.5038 - val_vowel_loss: 0.1548 - val_consonant_loss: 0.1457 - val_root_acc: 0.8599 - val_vowel_acc: 0.9543 - val_consonant_acc: 0.9560\n","Epoch 2/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 3.8056 - root_loss: 0.6108 - vowel_loss: 0.2542 - consonant_loss: 0.1999 - root_acc: 0.8255 - vowel_acc: 0.9219 - consonant_acc: 0.9363Epoch 1/60\n","1307/1307 [==============================] - 286s 219ms/step - loss: 3.8052 - root_loss: 0.6108 - vowel_loss: 0.2541 - consonant_loss: 0.1999 - root_acc: 0.8255 - vowel_acc: 0.9219 - consonant_acc: 0.9363 - val_loss: 2.2251 - val_root_loss: 0.3634 - val_vowel_loss: 0.1235 - val_consonant_loss: 0.1337 - val_root_acc: 0.8990 - val_vowel_acc: 0.9657 - val_consonant_acc: 0.9610\n","Epoch 3/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 3.2029 - root_loss: 0.5080 - vowel_loss: 0.2182 - consonant_loss: 0.1721 - root_acc: 0.8533 - vowel_acc: 0.9332 - consonant_acc: 0.9451Epoch 1/60\n","1307/1307 [==============================] - 283s 217ms/step - loss: 3.2029 - root_loss: 0.5081 - vowel_loss: 0.2182 - consonant_loss: 0.1721 - root_acc: 0.8533 - vowel_acc: 0.9332 - consonant_acc: 0.9451 - val_loss: 2.2171 - val_root_loss: 0.3706 - val_vowel_loss: 0.1336 - val_consonant_loss: 0.1113 - val_root_acc: 0.8916 - val_vowel_acc: 0.9626 - val_consonant_acc: 0.9647\n","Epoch 4/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 2.8538 - root_loss: 0.4508 - vowel_loss: 0.1947 - consonant_loss: 0.1555 - root_acc: 0.8695 - vowel_acc: 0.9415 - consonant_acc: 0.9512Epoch 1/60\n","1307/1307 [==============================] - 285s 218ms/step - loss: 2.8538 - root_loss: 0.4508 - vowel_loss: 0.1946 - consonant_loss: 0.1556 - root_acc: 0.8695 - vowel_acc: 0.9415 - consonant_acc: 0.9512 - val_loss: 1.7242 - val_root_loss: 0.2829 - val_vowel_loss: 0.0970 - val_consonant_loss: 0.1005 - val_root_acc: 0.9175 - val_vowel_acc: 0.9738 - val_consonant_acc: 0.9696\n","Epoch 5/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 2.6049 - root_loss: 0.4075 - vowel_loss: 0.1831 - consonant_loss: 0.1418 - root_acc: 0.8817 - vowel_acc: 0.9444 - consonant_acc: 0.9553Epoch 1/60\n","1307/1307 [==============================] - 285s 218ms/step - loss: 2.6047 - root_loss: 0.4075 - vowel_loss: 0.1832 - consonant_loss: 0.1418 - root_acc: 0.8817 - vowel_acc: 0.9444 - consonant_acc: 0.9553 - val_loss: 1.6128 - val_root_loss: 0.2709 - val_vowel_loss: 0.0830 - val_consonant_loss: 0.0934 - val_root_acc: 0.9243 - val_vowel_acc: 0.9796 - val_consonant_acc: 0.9730\n","Epoch 6/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 2.3928 - root_loss: 0.3736 - vowel_loss: 0.1678 - consonant_loss: 0.1317 - root_acc: 0.8905 - vowel_acc: 0.9493 - consonant_acc: 0.9584Epoch 1/60\n","1307/1307 [==============================] - 284s 217ms/step - loss: 2.3924 - root_loss: 0.3735 - vowel_loss: 0.1677 - consonant_loss: 0.1318 - root_acc: 0.8905 - vowel_acc: 0.9493 - consonant_acc: 0.9584 - val_loss: 1.4945 - val_root_loss: 0.2564 - val_vowel_loss: 0.0803 - val_consonant_loss: 0.0760 - val_root_acc: 0.9253 - val_vowel_acc: 0.9779 - val_consonant_acc: 0.9784\n","Epoch 7/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 2.2415 - root_loss: 0.3464 - vowel_loss: 0.1596 - consonant_loss: 0.1256 - root_acc: 0.8988 - vowel_acc: 0.9515 - consonant_acc: 0.9604Epoch 1/60\n","1307/1307 [==============================] - 285s 218ms/step - loss: 2.2411 - root_loss: 0.3464 - vowel_loss: 0.1596 - consonant_loss: 0.1256 - root_acc: 0.8988 - vowel_acc: 0.9515 - consonant_acc: 0.9604 - val_loss: 1.5210 - val_root_loss: 0.2433 - val_vowel_loss: 0.1087 - val_consonant_loss: 0.0739 - val_root_acc: 0.9298 - val_vowel_acc: 0.9660 - val_consonant_acc: 0.9788\n","Epoch 8/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 2.0951 - root_loss: 0.3241 - vowel_loss: 0.1473 - consonant_loss: 0.1189 - root_acc: 0.9046 - vowel_acc: 0.9552 - consonant_acc: 0.9630Epoch 1/60\n","1307/1307 [==============================] - 283s 217ms/step - loss: 2.0956 - root_loss: 0.3242 - vowel_loss: 0.1474 - consonant_loss: 0.1190 - root_acc: 0.9046 - vowel_acc: 0.9552 - consonant_acc: 0.9630 - val_loss: 1.4442 - val_root_loss: 0.2492 - val_vowel_loss: 0.0776 - val_consonant_loss: 0.0715 - val_root_acc: 0.9284 - val_vowel_acc: 0.9808 - val_consonant_acc: 0.9796\n","Epoch 9/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 2.0009 - root_loss: 0.3101 - vowel_loss: 0.1410 - consonant_loss: 0.1125 - root_acc: 0.9079 - vowel_acc: 0.9573 - consonant_acc: 0.9646Epoch 1/60\n","1307/1307 [==============================] - 284s 217ms/step - loss: 2.0012 - root_loss: 0.3102 - vowel_loss: 0.1410 - consonant_loss: 0.1125 - root_acc: 0.9078 - vowel_acc: 0.9573 - consonant_acc: 0.9646 - val_loss: 1.3726 - val_root_loss: 0.2307 - val_vowel_loss: 0.0795 - val_consonant_loss: 0.0704 - val_root_acc: 0.9339 - val_vowel_acc: 0.9796 - val_consonant_acc: 0.9804\n","Epoch 10/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 1.8953 - root_loss: 0.2927 - vowel_loss: 0.1342 - consonant_loss: 0.1074 - root_acc: 0.9132 - vowel_acc: 0.9594 - consonant_acc: 0.9668Epoch 1/60\n","1307/1307 [==============================] - 283s 216ms/step - loss: 1.8953 - root_loss: 0.2926 - vowel_loss: 0.1342 - consonant_loss: 0.1074 - root_acc: 0.9132 - vowel_acc: 0.9594 - consonant_acc: 0.9668 - val_loss: 1.4644 - val_root_loss: 0.2437 - val_vowel_loss: 0.0847 - val_consonant_loss: 0.0785 - val_root_acc: 0.9309 - val_vowel_acc: 0.9765 - val_consonant_acc: 0.9772\n","Epoch 11/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 1.8065 - root_loss: 0.2754 - vowel_loss: 0.1319 - consonant_loss: 0.1031 - root_acc: 0.9174 - vowel_acc: 0.9604 - consonant_acc: 0.9678Epoch 1/60\n","1307/1307 [==============================] - 286s 218ms/step - loss: 1.8065 - root_loss: 0.2753 - vowel_loss: 0.1319 - consonant_loss: 0.1032 - root_acc: 0.9174 - vowel_acc: 0.9604 - consonant_acc: 0.9678 - val_loss: 1.3771 - val_root_loss: 0.2216 - val_vowel_loss: 0.0907 - val_consonant_loss: 0.0729 - val_root_acc: 0.9368 - val_vowel_acc: 0.9736 - val_consonant_acc: 0.9787\n","Epoch 12/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 1.7472 - root_loss: 0.2680 - vowel_loss: 0.1267 - consonant_loss: 0.0984 - root_acc: 0.9191 - vowel_acc: 0.9619 - consonant_acc: 0.9691Epoch 1/60\n","1307/1307 [==============================] - 284s 217ms/step - loss: 1.7477 - root_loss: 0.2680 - vowel_loss: 0.1267 - consonant_loss: 0.0985 - root_acc: 0.9191 - vowel_acc: 0.9619 - consonant_acc: 0.9691 - val_loss: 1.3015 - val_root_loss: 0.2263 - val_vowel_loss: 0.0623 - val_consonant_loss: 0.0698 - val_root_acc: 0.9342 - val_vowel_acc: 0.9838 - val_consonant_acc: 0.9796\n","Epoch 13/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 1.6582 - root_loss: 0.2525 - vowel_loss: 0.1200 - consonant_loss: 0.0961 - root_acc: 0.9245 - vowel_acc: 0.9637 - consonant_acc: 0.9697Epoch 1/60\n"," 130/1307 [=>............................] - ETA: 1:16 - loss: 1.5372 - root_loss: 0.2651 - vowel_loss: 0.0817 - consonant_loss: 0.0772 - root_acc: 0.9285 - vowel_acc: 0.9783 - consonant_acc: 0.9784\n","Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","1307/1307 [==============================] - 286s 219ms/step - loss: 1.6585 - root_loss: 0.2526 - vowel_loss: 0.1200 - consonant_loss: 0.0960 - root_acc: 0.9245 - vowel_acc: 0.9637 - consonant_acc: 0.9697 - val_loss: 1.5372 - val_root_loss: 0.2651 - val_vowel_loss: 0.0817 - val_consonant_loss: 0.0772 - val_root_acc: 0.9285 - val_vowel_acc: 0.9783 - val_consonant_acc: 0.9784\n","Epoch 14/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 1.2553 - root_loss: 0.1876 - vowel_loss: 0.0932 - consonant_loss: 0.0752 - root_acc: 0.9422 - vowel_acc: 0.9714 - consonant_acc: 0.9767Epoch 1/60\n","1307/1307 [==============================] - 285s 218ms/step - loss: 1.2554 - root_loss: 0.1875 - vowel_loss: 0.0932 - consonant_loss: 0.0752 - root_acc: 0.9422 - vowel_acc: 0.9714 - consonant_acc: 0.9767 - val_loss: 1.2219 - val_root_loss: 0.2075 - val_vowel_loss: 0.0682 - val_consonant_loss: 0.0624 - val_root_acc: 0.9443 - val_vowel_acc: 0.9829 - val_consonant_acc: 0.9828\n","Epoch 15/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 1.1639 - root_loss: 0.1719 - vowel_loss: 0.0891 - consonant_loss: 0.0697 - root_acc: 0.9463 - vowel_acc: 0.9728 - consonant_acc: 0.9781Epoch 1/60\n","1307/1307 [==============================] - 285s 218ms/step - loss: 1.1640 - root_loss: 0.1719 - vowel_loss: 0.0891 - consonant_loss: 0.0697 - root_acc: 0.9463 - vowel_acc: 0.9728 - consonant_acc: 0.9781 - val_loss: 1.8537 - val_root_loss: 0.1948 - val_vowel_loss: 0.2871 - val_consonant_loss: 0.0711 - val_root_acc: 0.9436 - val_vowel_acc: 0.8940 - val_consonant_acc: 0.9793\n","Epoch 16/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 1.1251 - root_loss: 0.1665 - vowel_loss: 0.0846 - consonant_loss: 0.0684 - root_acc: 0.9474 - vowel_acc: 0.9737 - consonant_acc: 0.9783Epoch 1/60\n","1307/1307 [==============================] - 285s 218ms/step - loss: 1.1250 - root_loss: 0.1665 - vowel_loss: 0.0846 - consonant_loss: 0.0684 - root_acc: 0.9474 - vowel_acc: 0.9736 - consonant_acc: 0.9783 - val_loss: 0.9577 - val_root_loss: 0.1632 - val_vowel_loss: 0.0507 - val_consonant_loss: 0.0510 - val_root_acc: 0.9549 - val_vowel_acc: 0.9871 - val_consonant_acc: 0.9861\n","Epoch 17/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 1.1059 - root_loss: 0.1631 - vowel_loss: 0.0839 - consonant_loss: 0.0672 - root_acc: 0.9492 - vowel_acc: 0.9742 - consonant_acc: 0.9789Epoch 1/60\n","1307/1307 [==============================] - 284s 218ms/step - loss: 1.1059 - root_loss: 0.1631 - vowel_loss: 0.0839 - consonant_loss: 0.0672 - root_acc: 0.9492 - vowel_acc: 0.9742 - consonant_acc: 0.9789 - val_loss: 1.0457 - val_root_loss: 0.1719 - val_vowel_loss: 0.0580 - val_consonant_loss: 0.0615 - val_root_acc: 0.9517 - val_vowel_acc: 0.9846 - val_consonant_acc: 0.9836\n","Epoch 18/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 1.0641 - root_loss: 0.1568 - vowel_loss: 0.0803 - consonant_loss: 0.0653 - root_acc: 0.9511 - vowel_acc: 0.9754 - consonant_acc: 0.9794Epoch 1/60\n"," 130/1307 [=>............................] - ETA: 1:16 - loss: 1.0211 - root_loss: 0.1734 - vowel_loss: 0.0521 - consonant_loss: 0.0570 - root_acc: 0.9532 - vowel_acc: 0.9874 - consonant_acc: 0.9866\n","Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","1307/1307 [==============================] - 283s 217ms/step - loss: 1.0639 - root_loss: 0.1568 - vowel_loss: 0.0803 - consonant_loss: 0.0653 - root_acc: 0.9511 - vowel_acc: 0.9754 - consonant_acc: 0.9794 - val_loss: 1.0211 - val_root_loss: 0.1734 - val_vowel_loss: 0.0521 - val_consonant_loss: 0.0570 - val_root_acc: 0.9532 - val_vowel_acc: 0.9874 - val_consonant_acc: 0.9866\n","Epoch 19/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 0.8656 - root_loss: 0.1247 - vowel_loss: 0.0679 - consonant_loss: 0.0543 - root_acc: 0.9599 - vowel_acc: 0.9789 - consonant_acc: 0.9830Epoch 1/60\n","1307/1307 [==============================] - 284s 218ms/step - loss: 0.8658 - root_loss: 0.1248 - vowel_loss: 0.0679 - consonant_loss: 0.0543 - root_acc: 0.9599 - vowel_acc: 0.9789 - consonant_acc: 0.9830 - val_loss: 0.8791 - val_root_loss: 0.1492 - val_vowel_loss: 0.0451 - val_consonant_loss: 0.0490 - val_root_acc: 0.9589 - val_vowel_acc: 0.9887 - val_consonant_acc: 0.9877\n","Epoch 20/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 0.8199 - root_loss: 0.1171 - vowel_loss: 0.0642 - consonant_loss: 0.0529 - root_acc: 0.9619 - vowel_acc: 0.9801 - consonant_acc: 0.9831Epoch 1/60\n","1307/1307 [==============================] - 285s 218ms/step - loss: 0.8197 - root_loss: 0.1171 - vowel_loss: 0.0642 - consonant_loss: 0.0529 - root_acc: 0.9619 - vowel_acc: 0.9801 - consonant_acc: 0.9831 - val_loss: 1.0019 - val_root_loss: 0.1698 - val_vowel_loss: 0.0548 - val_consonant_loss: 0.0528 - val_root_acc: 0.9555 - val_vowel_acc: 0.9865 - val_consonant_acc: 0.9860\n","Epoch 21/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 0.7835 - root_loss: 0.1124 - vowel_loss: 0.0625 - consonant_loss: 0.0488 - root_acc: 0.9635 - vowel_acc: 0.9804 - consonant_acc: 0.9844Epoch 1/60\n"," 130/1307 [=>............................] - ETA: 1:16 - loss: 0.8985 - root_loss: 0.1542 - vowel_loss: 0.0443 - consonant_loss: 0.0496 - root_acc: 0.9590 - vowel_acc: 0.9893 - consonant_acc: 0.9874\n","Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","1307/1307 [==============================] - 284s 217ms/step - loss: 0.7833 - root_loss: 0.1123 - vowel_loss: 0.0625 - consonant_loss: 0.0488 - root_acc: 0.9635 - vowel_acc: 0.9804 - consonant_acc: 0.9844 - val_loss: 0.8985 - val_root_loss: 0.1542 - val_vowel_loss: 0.0443 - val_consonant_loss: 0.0496 - val_root_acc: 0.9590 - val_vowel_acc: 0.9893 - val_consonant_acc: 0.9874\n","Epoch 22/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 0.7003 - root_loss: 0.0983 - vowel_loss: 0.0568 - consonant_loss: 0.0455 - root_acc: 0.9682 - vowel_acc: 0.9822 - consonant_acc: 0.9854Epoch 1/60\n","1307/1307 [==============================] - 284s 217ms/step - loss: 0.7006 - root_loss: 0.0984 - vowel_loss: 0.0568 - consonant_loss: 0.0455 - root_acc: 0.9682 - vowel_acc: 0.9822 - consonant_acc: 0.9854 - val_loss: 0.8732 - val_root_loss: 0.1495 - val_vowel_loss: 0.0424 - val_consonant_loss: 0.0494 - val_root_acc: 0.9609 - val_vowel_acc: 0.9906 - val_consonant_acc: 0.9877\n","Epoch 23/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 0.6688 - root_loss: 0.0941 - vowel_loss: 0.0547 - consonant_loss: 0.0428 - root_acc: 0.9694 - vowel_acc: 0.9826 - consonant_acc: 0.9865Epoch 1/60\n"," 130/1307 [=>............................] - ETA: 1:17 - loss: 0.8938 - root_loss: 0.1537 - vowel_loss: 0.0441 - consonant_loss: 0.0490 - root_acc: 0.9607 - vowel_acc: 0.9897 - consonant_acc: 0.9880\n","Epoch 00023: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","1307/1307 [==============================] - 284s 217ms/step - loss: 0.6690 - root_loss: 0.0942 - vowel_loss: 0.0547 - consonant_loss: 0.0428 - root_acc: 0.9693 - vowel_acc: 0.9826 - consonant_acc: 0.9865 - val_loss: 0.8938 - val_root_loss: 0.1537 - val_vowel_loss: 0.0441 - val_consonant_loss: 0.0490 - val_root_acc: 0.9607 - val_vowel_acc: 0.9897 - val_consonant_acc: 0.9880\n","Epoch 24/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 0.6246 - root_loss: 0.0867 - vowel_loss: 0.0515 - consonant_loss: 0.0411 - root_acc: 0.9714 - vowel_acc: 0.9838 - consonant_acc: 0.9868Epoch 1/60\n","1307/1307 [==============================] - 285s 218ms/step - loss: 0.6246 - root_loss: 0.0867 - vowel_loss: 0.0515 - consonant_loss: 0.0411 - root_acc: 0.9714 - vowel_acc: 0.9838 - consonant_acc: 0.9868 - val_loss: 0.8732 - val_root_loss: 0.1503 - val_vowel_loss: 0.0425 - val_consonant_loss: 0.0483 - val_root_acc: 0.9615 - val_vowel_acc: 0.9899 - val_consonant_acc: 0.9874\n","Epoch 25/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 0.6082 - root_loss: 0.0847 - vowel_loss: 0.0502 - consonant_loss: 0.0396 - root_acc: 0.9721 - vowel_acc: 0.9839 - consonant_acc: 0.9872Epoch 1/60\n"," 130/1307 [=>............................] - ETA: 1:19 - loss: 0.8702 - root_loss: 0.1498 - vowel_loss: 0.0424 - consonant_loss: 0.0479 - root_acc: 0.9621 - vowel_acc: 0.9897 - consonant_acc: 0.9885\n","Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","1307/1307 [==============================] - 285s 218ms/step - loss: 0.6082 - root_loss: 0.0847 - vowel_loss: 0.0502 - consonant_loss: 0.0396 - root_acc: 0.9721 - vowel_acc: 0.9839 - consonant_acc: 0.9872 - val_loss: 0.8702 - val_root_loss: 0.1498 - val_vowel_loss: 0.0424 - val_consonant_loss: 0.0479 - val_root_acc: 0.9621 - val_vowel_acc: 0.9897 - val_consonant_acc: 0.9885\n","Epoch 26/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 0.5897 - root_loss: 0.0817 - vowel_loss: 0.0486 - consonant_loss: 0.0391 - root_acc: 0.9731 - vowel_acc: 0.9847 - consonant_acc: 0.9875Epoch 1/60\n","1307/1307 [==============================] - 284s 218ms/step - loss: 0.5896 - root_loss: 0.0816 - vowel_loss: 0.0486 - consonant_loss: 0.0391 - root_acc: 0.9731 - vowel_acc: 0.9847 - consonant_acc: 0.9875 - val_loss: 0.8709 - val_root_loss: 0.1495 - val_vowel_loss: 0.0426 - val_consonant_loss: 0.0484 - val_root_acc: 0.9621 - val_vowel_acc: 0.9899 - val_consonant_acc: 0.9881\n","Epoch 27/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 0.5686 - root_loss: 0.0775 - vowel_loss: 0.0480 - consonant_loss: 0.0382 - root_acc: 0.9743 - vowel_acc: 0.9846 - consonant_acc: 0.9875Epoch 1/60\n","1307/1307 [==============================] - 286s 219ms/step - loss: 0.5686 - root_loss: 0.0775 - vowel_loss: 0.0480 - consonant_loss: 0.0382 - root_acc: 0.9743 - vowel_acc: 0.9846 - consonant_acc: 0.9875 - val_loss: 0.8859 - val_root_loss: 0.1483 - val_vowel_loss: 0.0496 - val_consonant_loss: 0.0480 - val_root_acc: 0.9616 - val_vowel_acc: 0.9870 - val_consonant_acc: 0.9879\n","Epoch 28/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 0.5751 - root_loss: 0.0793 - vowel_loss: 0.0482 - consonant_loss: 0.0378 - root_acc: 0.9740 - vowel_acc: 0.9845 - consonant_acc: 0.9876Epoch 1/60\n","1307/1307 [==============================] - 284s 217ms/step - loss: 0.5751 - root_loss: 0.0793 - vowel_loss: 0.0482 - consonant_loss: 0.0377 - root_acc: 0.9740 - vowel_acc: 0.9845 - consonant_acc: 0.9876 - val_loss: 0.8737 - val_root_loss: 0.1500 - val_vowel_loss: 0.0430 - val_consonant_loss: 0.0482 - val_root_acc: 0.9615 - val_vowel_acc: 0.9896 - val_consonant_acc: 0.9886\n","Epoch 29/60\n","1306/1307 [============================>.] - ETA: 0s - loss: 0.5590 - root_loss: 0.0767 - vowel_loss: 0.0469 - consonant_loss: 0.0371 - root_acc: 0.9743 - vowel_acc: 0.9850 - consonant_acc: 0.9881Epoch 1/60\n"," 130/1307 [=>............................] - ETA: 1:19 - loss: 0.8787 - root_loss: 0.1518 - vowel_loss: 0.0421 - consonant_loss: 0.0485 - root_acc: 0.9619 - vowel_acc: 0.9899 - consonant_acc: 0.9882\n","Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","1307/1307 [==============================] - 285s 218ms/step - loss: 0.5591 - root_loss: 0.0768 - vowel_loss: 0.0469 - consonant_loss: 0.0371 - root_acc: 0.9742 - vowel_acc: 0.9850 - consonant_acc: 0.9881 - val_loss: 0.8787 - val_root_loss: 0.1518 - val_vowel_loss: 0.0421 - val_consonant_loss: 0.0485 - val_root_acc: 0.9619 - val_vowel_acc: 0.9899 - val_consonant_acc: 0.9882\n","Epoch 30/60\n"," 116/1307 [=>............................] - ETA: 4:09 - loss: 0.5710 - root_loss: 0.0783 - vowel_loss: 0.0474 - consonant_loss: 0.0386 - root_acc: 0.9738 - vowel_acc: 0.9843 - consonant_acc: 0.9876Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qk0r642Dcoq1","colab_type":"code","outputId":"3f09e6e3-0622-4b4c-f579-6c5443e37c0e","executionInfo":{"status":"ok","timestamp":1583392026742,"user_tz":300,"elapsed":6636,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"04069451015857955148"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","model_name = 'densenet_aug_3.h5'\n","save_dir = os.path.join(\"/content/drive/My Drive/Colab Notebooks/bengaliai-cv19/\", 'saved_models')\n","\n","# Save model and weights\n","if not os.path.isdir(save_dir):\n","    os.makedirs(save_dir)\n","model_path = os.path.join(save_dir, model_name)\n","model.save(model_path)\n","print('Saved trained model at %s ' % model_path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Saved trained model at /content/drive/My Drive/Colab Notebooks/bengaliai-cv19/saved_models/densenet_aug_3.h5 \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IxmePYm5EZGT","colab_type":"code","outputId":"415d861b-34ea-4f53-f29e-a9f29b794f4c","executionInfo":{"status":"ok","timestamp":1583384539790,"user_tz":300,"elapsed":40162,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"04069451015857955148"}},"colab":{"base_uri":"https://localhost:8080/","height":188}},"source":["load = keras.models.load_model(\"/content/drive/My Drive/Colab Notebooks/bengaliai-cv19/saved_models/densenet_aug_1.h5\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YHnoTOPVEi54","colab_type":"code","outputId":"029f32be-84f2-477f-cef4-f0258b2d22bd","executionInfo":{"status":"ok","timestamp":1583384566052,"user_tz":300,"elapsed":1149,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"04069451015857955148"}},"colab":{"base_uri":"https://localhost:8080/","height":487}},"source":["load.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 96, 96, 1)]  0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 96, 96, 3)    30          input_2[0][0]                    \n","__________________________________________________________________________________________________\n","densenet121 (Model)             multiple             7037504     conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 1024)         0           densenet121[1][0]                \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 1024)         4096        global_average_pooling2d[0][0]   \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 1024)         0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1024)         1049600     dropout[0][0]                    \n","__________________________________________________________________________________________________\n","root (Dense)                    (None, 168)          172200      dense[0][0]                      \n","__________________________________________________________________________________________________\n","vowel (Dense)                   (None, 11)           11275       dense[0][0]                      \n","__________________________________________________________________________________________________\n","consonant (Dense)               (None, 7)            7175        dense[0][0]                      \n","==================================================================================================\n","Total params: 8,281,880\n","Trainable params: 8,196,184\n","Non-trainable params: 85,696\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kivUdrbME-iH","colab_type":"code","outputId":"553329c2-a10c-483b-c9c2-7cbd4ea0f731","executionInfo":{"status":"ok","timestamp":1583384624632,"user_tz":300,"elapsed":1207,"user":{"displayName":"Kevin Yang","photoUrl":"","userId":"04069451015857955148"}},"colab":{"base_uri":"https://localhost:8080/","height":487}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 96, 96, 1)]  0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 96, 96, 3)    30          input_2[0][0]                    \n","__________________________________________________________________________________________________\n","densenet121 (Model)             multiple             7037504     conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 1024)         0           densenet121[1][0]                \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 1024)         4096        global_average_pooling2d[0][0]   \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 1024)         0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1024)         1049600     dropout[0][0]                    \n","__________________________________________________________________________________________________\n","root (Dense)                    (None, 168)          172200      dense[0][0]                      \n","__________________________________________________________________________________________________\n","vowel (Dense)                   (None, 11)           11275       dense[0][0]                      \n","__________________________________________________________________________________________________\n","consonant (Dense)               (None, 7)            7175        dense[0][0]                      \n","==================================================================================================\n","Total params: 8,281,880\n","Trainable params: 8,196,184\n","Non-trainable params: 85,696\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3awq_NTne1p9","colab_type":"code","colab":{}},"source":["preds_dict = {\n","    'grapheme_root': [],\n","    'vowel_diacritic': [],\n","    'consonant_diacritic': []\n","}\n","components = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\n","target=[] \n","row_id=[] \n","\n","model_1 = keras.models.load_model(\"/content/drive/My Drive/Colab Notebooks/bengaliai-cv19/saved_models/resnet34_aug_1.h5\")\n","model_2 = keras.models.load_model(\"/content/drive/My Drive/Colab Notebooks/bengaliai-cv19/saved_models/densenet_aug_1.h5\")\n","\n","for i in range(4):\n","    testfile_0 = pd.read_parquet('/content/drive/My Drive/Untitled folder/bengaliai-cv19/test_image_data_{}.parquet'.format(i))\n","    testfile_0.set_index('image_id', inplace=True)\n","    \n","    testdata = np.reshape(testfile_0.values, (testfile_0.shape[0], 137, 236, 1))\n","\n","    new_data = [0] * testdata.shape[0]\n","\n","    for j in tqdm(range(testdata.shape[0])):\n","\n","        curpic = testdata[j, :, :, 0]\n","        # curpic = np.array(curpic,dtype=np.float)\n","        (x1, x2, y1, y2) = findEdge(curpic, 200)\n","        \n","        curpic_2 = np.stack([i[x1:x2] for i in curpic[y1:y2]],axis=0)\n","        del curpic\n","        newpic = changeshape(curpic_2, 96, 96) / 255\n","        del curpic_2\n","        new_data[j] = newpic\n","        del newpic\n","\n","    new_data = np.reshape(np.stack(new_data), (len(new_data), 96, 96, 1))\n","    \n","    preds_1 = model_1.predict(new_data)\n","    preds_2 = model_2.predict(new_data)\n","\n","    for k, p in enumerate(preds_dict):\n","        preds_dict[p] = np.argmax((preds_1[k]+preds_2[k])/2, axis=1)\n","\n","    for l,id in enumerate(testfile_0.index.values):  \n","        for comp in components:\n","            id_sample=str(id)+'_'+comp\n","            row_id.append(id_sample)\n","            target.append(preds_dict[comp][l])\n","    del testfile_0\n","\n","df_sample = pd.DataFrame(\n","    {\n","        'row_id': row_id,\n","        'target':target\n","    },\n","    columns = ['row_id','target'] \n",")\n","df_sample.to_csv('submission.csv',index=False)\n","df_sample"],"execution_count":0,"outputs":[]}]}